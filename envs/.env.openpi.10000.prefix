# =============================================================================
# PaliGemma Training Configuration (OpenPI pi0.5_base)
# =============================================================================
# This configuration uses PaliGemma weights extracted from OpenPI's pi0.5_base.
#
# pi0.5_base is pre-trained on 10k+ hours of robot manipulation data,
# providing better generalization for robotics tasks compared to vanilla PaliGemma.
#
# The checkpoint is automatically downloaded and extracted by setup.sh from:
#   gs://openpi-assets/checkpoints/pi05_base
#
# Usage:
#   python scripts/03_train_production.py --env envs/.env.openpi
# =============================================================================

# =============================================================================
# Debugging Flags - Enable comprehensive debugging output
# =============================================================================
# Set DEBUG_TRAINING=1 to enable ALL debugging checks
DEBUG_TRAINING=0

# Individual debug flags (automatically enabled if DEBUG_TRAINING=1)
# MODEL_DEBUG_EMBEDDING=1   # Log embedding details in paligemma.py
# MODEL_DEBUG_FORWARD=1     # Log forward pass details in paligemma.py
# VALIDATE_BATCH_IMAGES=1   # Validate image data in batches
# # Experiment name
EXPERIMENT_NAME=pi05_paligemma_training

# =============================================================================
# Model Configuration
# =============================================================================
# PaliGemma weights extracted from OpenPI pi0.5_base (downloaded by setup.sh)
MODEL_CHECKPOINT_PATH=./checkpoints/pi05_base_paligemma.npz
# No URL needed - setup.sh handles the extraction from pi0.5_base

# Tokenizer (use existing one from Kaggle download)
MODEL_TOKENIZER_PATH=./assets/paligemma_tokenizer.model

# Model architecture (same as standard PaliGemma)
MODEL_LLM_VARIANT=gemma_2b
MODEL_VOCAB_SIZE=257152
MODEL_IMG_SIZE=224
MODEL_IMG_VARIANT=So400m/14
MODEL_IMG_POOL_TYPE=none
MODEL_IMG_SCAN=true
MODEL_IMG_DTYPE_MM=float16

# =============================================================================
# Training Configuration
# =============================================================================
# Which parameters to train
# Options: attention_only, full_llm, full_model
TRAINABLE_PARAMS=full_model

# Learning rate and schedule
LEARNING_RATE=5e-5
LR_SCHEDULE=cosine
WARMUP_PERCENT=0.10

# Batch size and epochs
PRECISION=bfloat16           
USE_PMAP=false                
BATCH_SIZE=4
NUM_EPOCHS=20
GRADIENT_ACCUMULATION_STEPS=8


# Gradient clipping and accumulation
MAX_GRAD_NORM=1.0
# GRADIENT_ACCUMULATION_STEPS=16

# Random seed for reproducibility
SEED=42

# =============================================================================
# Data Configuration
# =============================================================================
DATA_BASE_DIR=/workspace/paligemma_jax_training/../XVR
DATA_TRAIN_FILE=train.jsonl
DATA_VALID_FILE=valid.jsonl
# DATA_EVAL_FILE=xvr_eval.jsonl
DATA_IMAGE_DIR=images

# Sequence settings
MAX_SEQ_LENGTH=512
SHUFFLE_BUFFER_SIZE=1000

# Prompt prefix for model
PROMPT_PREFIX=

# Training strategy: Train on prefix (question) tokens
# TRAIN_ON_PREFIX=1: Train on question+answer (more gradient signal, better image utilization)
# TRAIN_ON_PREFIX=0: Train on answer only (default PaliGemma, less gradient signal)
TRAIN_ON_PREFIX=1

# Optional: limit samples for faster iteration (comment out for full training)
MAX_TRAIN_SAMPLES=10000
MAX_EVAL_SAMPLES=1000

# =============================================================================
# Logging and Checkpointing
# =============================================================================
OUTPUT_DIR=./outputs/openpi_production

# Logging frequency
LOG_EVERY=1
EVAL_EVERY=10
CHECKPOINT_EVERY=1000
MAX_CHECKPOINTS_TO_KEEP=3

# Weights & Biases (optional)
USE_WANDB=true
WANDB_PROJECT=paligemma-xvr-openpi
WANDB_ENTITY=schaeck
WANDB_MODE=online

# =============================================================================
# Evaluation Configuration
# =============================================================================
# Number of examples to evaluate (null = all)
# EVAL_NUM_EXAMPLES=100
EVAL_BATCH_SIZE=4
EVAL_SAMPLER=greedy

# =============================================================================
# System Configuration
# =============================================================================
XLA_MEM_FRACTION=0.9
TF_ALLOW_GROWTH=true
BIG_VISION_PATH=/workspace/paligemma_jax_training/../big_vision
