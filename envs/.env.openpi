# =============================================================================
# OpenPI PaliGemma Training Configuration
# =============================================================================
# This configuration uses the OpenPI PaliGemma checkpoint as the starting point
# for training. The checkpoint will be downloaded automatically if not present.
#
# Usage:
#   python scripts/03_train_production.py --env .env.openpi
# =============================================================================

# Experiment name
EXPERIMENT_NAME=openpi_paligemma_training

# =============================================================================
# Model Configuration
# =============================================================================
# OpenPI PaliGemma checkpoint URL (will be downloaded if not exists locally)
MODEL_CHECKPOINT_PATH=./openpi_paligemma_pt_224.npz
MODEL_CHECKPOINT_URL=https://storage.googleapis.com/vertex-model-garden-paligemma-us/paligemma/pt_224.npz

# Tokenizer (use existing one from Kaggle download)
MODEL_TOKENIZER_PATH=./paligemma_tokenizer.model

# Model architecture (same as standard PaliGemma)
MODEL_LLM_VARIANT=gemma_2b
MODEL_VOCAB_SIZE=257152
MODEL_IMG_SIZE=224
MODEL_IMG_VARIANT=So400m/14
MODEL_IMG_POOL_TYPE=none
MODEL_IMG_SCAN=true
MODEL_IMG_DTYPE_MM=float16

# =============================================================================
# Training Configuration
# =============================================================================
# Which parameters to train
# Options: attention_only, full_llm, full_model
TRAINABLE_PARAMS=attention_only

# Learning rate and schedule
LEARNING_RATE=0.0002
LR_SCHEDULE=cosine
WARMUP_PERCENT=0.10

# Batch size and epochs
BATCH_SIZE=8
NUM_EPOCHS=2

# Gradient clipping
MAX_GRAD_NORM=1.0

# Random seed for reproducibility
SEED=42

# =============================================================================
# Data Configuration
# =============================================================================
DATA_BASE_DIR=/home/suchae/pi_workspace/XVR
DATA_TRAIN_FILE=train.jsonl
DATA_VALID_FILE=valid.jsonl
# DATA_EVAL_FILE=xvr_eval.jsonl
DATA_IMAGE_DIR=images

# Sequence settings
MAX_SEQ_LENGTH=256
SHUFFLE_BUFFER_SIZE=1000
NUM_PARALLEL_CALLS=8

# Prompt prefix for model
PROMPT_PREFIX=answer en

# Optional: limit samples for faster iteration (comment out for full training)
# MAX_TRAIN_SAMPLES=1000
# MAX_EVAL_SAMPLES=100

# =============================================================================
# Logging and Checkpointing
# =============================================================================
OUTPUT_DIR=./outputs/openpi_production

# Logging frequency
LOG_EVERY=50
EVAL_EVERY=500
CHECKPOINT_EVERY=5000
MAX_CHECKPOINTS_TO_KEEP=3

# Weights & Biases (optional)
USE_WANDB=false
WANDB_PROJECT=paligemma-xvr-openpi
# WANDB_ENTITY=your-entity

# =============================================================================
# Evaluation Configuration
# =============================================================================
# Number of examples to evaluate (null = all)
# EVAL_NUM_EXAMPLES=100
EVAL_BATCH_SIZE=4
EVAL_SAMPLER=greedy
EVAL_NUM_BEAMS=4

# =============================================================================
# System Configuration
# =============================================================================
XLA_MEM_FRACTION=0.9
SHARDING_STRATEGY=fsdp
TF_ALLOW_GROWTH=true
BIG_VISION_PATH=/home/suchae/pi_workspace/big_vision
