# =============================================================================
# PaliGemma Training Configuration (OpenPI pi0.5_base)
# =============================================================================
# This configuration uses PaliGemma weights extracted from OpenPI's pi0.5_base.
#
# pi0.5_base is pre-trained on 10k+ hours of robot manipulation data,
# providing better generalization for robotics tasks compared to vanilla PaliGemma.
#
# The checkpoint is automatically downloaded and extracted by setup.sh from:
#   gs://openpi-assets/checkpoints/pi05_base
#
# Usage:
#   python scripts/03_train_production.py --env envs/.env.openpi
# =============================================================================

# Experiment name
EXPERIMENT_NAME=pi05_paligemma_training

# =============================================================================
# Model Configuration
# =============================================================================
# PaliGemma weights extracted from OpenPI pi0.5_base (downloaded by setup.sh)
MODEL_CHECKPOINT_PATH=./checkpoints/pi05_base_paligemma.npz
# No URL needed - setup.sh handles the extraction from pi0.5_base

# Tokenizer (use existing one from Kaggle download)
MODEL_TOKENIZER_PATH=./assets/paligemma_tokenizer.model

# Model architecture (same as standard PaliGemma)
MODEL_LLM_VARIANT=gemma_2b
MODEL_VOCAB_SIZE=257152
MODEL_IMG_SIZE=224
MODEL_IMG_VARIANT=So400m/14
MODEL_IMG_POOL_TYPE=none
MODEL_IMG_SCAN=true
MODEL_IMG_DTYPE_MM=float16

# =============================================================================
# Training Configuration
# =============================================================================
# Which parameters to train
# Options: attention_only, full_llm, full_model
TRAINABLE_PARAMS=attention_only

# Learning rate and schedule
LEARNING_RATE=0.0002
LR_SCHEDULE=cosine
WARMUP_PERCENT=0.10

# Batch size and epochs
BATCH_SIZE=8
NUM_EPOCHS=2

# Gradient clipping
MAX_GRAD_NORM=1.0

# Random seed for reproducibility
SEED=42

# =============================================================================
# Data Configuration
# =============================================================================
DATA_BASE_DIR=/home/suchae/pi_workspace/XVR
DATA_TRAIN_FILE=train.jsonl
DATA_VALID_FILE=valid.jsonl
# DATA_EVAL_FILE=xvr_eval.jsonl
DATA_IMAGE_DIR=images

# Sequence settings
MAX_SEQ_LENGTH=256
SHUFFLE_BUFFER_SIZE=1000
NUM_PARALLEL_CALLS=8

# Prompt prefix for model
PROMPT_PREFIX=answer en

# Optional: limit samples for faster iteration (comment out for full training)
# MAX_TRAIN_SAMPLES=1000
# MAX_EVAL_SAMPLES=100

# =============================================================================
# Logging and Checkpointing
# =============================================================================
OUTPUT_DIR=./outputs/openpi_production

# Logging frequency
LOG_EVERY=50
EVAL_EVERY=500
CHECKPOINT_EVERY=5000
MAX_CHECKPOINTS_TO_KEEP=3

# Weights & Biases (optional)
USE_WANDB=false
WANDB_PROJECT=paligemma-xvr-openpi
# WANDB_ENTITY=your-entity

# =============================================================================
# Evaluation Configuration
# =============================================================================
# Number of examples to evaluate (null = all)
# EVAL_NUM_EXAMPLES=100
EVAL_BATCH_SIZE=4
EVAL_SAMPLER=greedy
EVAL_NUM_BEAMS=4

# =============================================================================
# System Configuration
# =============================================================================
XLA_MEM_FRACTION=0.9
SHARDING_STRATEGY=fsdp
TF_ALLOW_GROWTH=true
BIG_VISION_PATH=/home/suchae/pi_workspace/big_vision
